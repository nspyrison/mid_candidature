---
#setspace: doublespacing
output: 
    ### pdf_document2 changes how fig references work to /@ref() :
    bookdown::pdf_document2: 
      includes:
        #in_header: preamble.sty ### Preamble covered in .yaml `header-includes:`
        before_body: title.sty
      keep_tex: yes
      number_sections: yes
      #toc_depth: 2
      ### also needed for fig cross references:
      fig_caption: yes
bibliography: thesisrefs.bib
fontsize: 11
urlcolor: blue
### LaTeX preamble
header-includes: 
 - \usepackage{setspace} ### for title page spacing
 - \usepackage{hyperref} ### for all sorts of linking
 - \usepackage{graphicx} ### to insert Monash crest

---

```{r include=FALSE, cache=FALSE}
### For appendix, somehow causing issue while commented.
        # after_body: spyrison-cook-marriott.md
        # after_body: "`r knitr::knit('../spinifex_study/paper/spyrison-cook-marriott.Rmd')`"

### Keep it simple! No R code in .rmd, use a seprate .r script if need be.
library(knitr) 
knitr::opts_chunk$set(fig.align = "center",
                      echo = F,
                      fig.pos = "h",
                      out.extra = ''
                      #message = FALSE,
                      #warning = FALSE,
                      #error = FALSE,
                      #collapse = TRUE,
                      #comment = "",
                      #cache = F, 
                      #cache.lazy = FALSE
                      
)

# <!-- # cheatsheet {#sec:cheatsheet}-->
# <!-- A bib reference [@wickham_visualizing_2015].  -->
# <!-- A [Section intro](#sec:cheatsheet) reference, alternatively, section \ref{sec:intro} (with no @; \\ref{sec:intro}). -->
# <!-- ```{r crest, echo=FALSE, out.height = "10%", out.width = "10%", fig.cap = "A caption for crest figure"} -->
# <!-- knitr::include_graphics("figures/can_con/crest.jpg") -->
# <!-- ``` -->
# <!-- A figure \@ref(fig:crest) reference (with @; \\@ref(fig:crest). -->
# ref:myFig-cap) Seprate fig cap
# ```{r step2, echo=F, fig.cap = "(ref:myFig-cap)"}
# # <!-- knitr::include_graphics("figures/can_con/crest.jpg") -->
# ```

```

<!-- Report length: 3,000 -  5,000 words ("6 - 10 pgs" of words) -->
<!-- Proposed report  structure: -->
<!-- # Introduction – Summary of the Research Project: -->
<!-- ## Motivation/current state of the field and an identification of a gap in knowledge -->
<!-- ## Research Objective -->
<!-- ## Methodology/method/data-collection & analysis -->
<!-- # Progress since confirmation -->
<!-- # Proposed Thesis Structure – including a table of the writing  status -->
<!-- # Publications arising from the thesis – published or planned -->
<!-- # Potential issues for the panel to consider -->
<!-- ## Resources/funding requests -->
<!-- ## Absence of student/supervisor -->
<!-- ## Other issues. -->


<!-- An abstract summarizes, usually in one paragraph of 300 words or less, the major aspects of the entire paper in a prescribed sequence that includes: 1) the overall purpose of the study and the research problem(s) you investigated; 2) the basic design of the study; 3) major findings or trends found as a result of your analysis; and, 4) a summary of your interpretations and conclusions. -->


# Introduction {#sec:intro}

## Motivation 
<!-- objectively, why research is important -->

<!-- Visuals are important for EDA -->
The term exploratory data analysis was coined by @tukey_exploratory_1977, who leaves it as an intentionally broad term that encompasses the initial summarization and visualization of a data set. This is a critical first step of checking for realistic values and validating model assumptions. It may be tempting to review a series of summary statistics to check model assumptions. However, there are known datasets where the same summary statistics miss glaringly obvious visual patterns [@anscombe_graphs_1973; @matejka_same_2017]. It is strikingly simple to look at the wrong, or incomplete set of statistics needed to validate assumptions. Data visualization is fast, versatile, and robust relative to the alternative of numeric statistical summarization. Data visualization does and must remain a primary component of data analysis and model validation.

Consider tabular data containing many attributes (I will use attribute and variable as synonymous). Visualization of this ubiquitous type of dataset is key to its understanding and exploration. Visualization of spaces in more than 3 dimensions quickly becomes problematic. We will discuss the use of linear projections to mitigate this obstacle. The motivation for this research is two-fold: expand the dimensionality support and improve the understanding from such visualizations. 

## Current state of the field

<!-- Adding plotting dimensions -->
Consider plotting 2 variables as an XY scatterplot. To add a 3rd variable append the z-axis orthogonal (right angle to) the XY plane. Increasing dimensionality furth is not so trivial solved. To resolve this, we will introduce the basis vector and linear projections before traditional _discreate_ method, more recent _continuous_ methods and then discuss user control

Mathematically, a 'basis' is an orthonormal set of `d` element vectors, where each element vector is a linear combination of `p` elements in vector-space.  That is to say, a basis defines the direction and magnitude each of the `p` attributes contributes to every direction of the `d`-dimensional projection space. Consider a projection down to 2D. The basis defining this projection can be visually displayed as a unit circle with `p` line segments stemming from the origin as shown in figure \@ref(fig:basis).

```{r basis, echo = FALSE, out.width = "60%",                          fig.cap = "Illustration of a basis projecting 6 attributes down to 2 dimensions. The black line segments indicate the magnitude and direction a variable contributes to the projection."}
knitr::include_graphics("./figures/basis.png")
```


Many methods identify one or more projections of interest. For instance, scatterplot matrices [@chambers_graphical_1983] can be used to rapidly valid univariate supports and distributions. Principal component analysis [PCA; @pearson_liii._1901] and biplots [@gabriel_biplot_1971] highlight full sample variation. Linear discriminant analysis [@fisher_use_1936] and penalized discriminant analysis [@hastie_penalized_1995] can be used to identify projection with cluster separation. These are great techniques and all applicants for numeric data with many attributes, however, they have two notable features: they show only 1 or several _discrete_ projections and they do not allow for an analyst to steer or control.



## From discrete to continuous

<!-- Grand Tour -->
The above methods have suggested a _discrete_ number of linear projections to look at. At the same time, the stool example illustrates that looking at intermediate views improves understanding. A _continuous_ animation of the object being rotated would improve this understanding even further. This is analogous to the idea of a data visualization _tour_[@asimov_grand_1985; @buja_grand_1986]. A tour produces a relatively high number of linear projections and views them in quick succession, typically as an animation. When the bases have a relatively small change in the contributions the projections are much closer. Single points and features can be tracked and follow from projection to projection allowing for a better understanding of the local structure. 

<!-- knowledge gap -->
The path that a tour animates is a crucial feature. There are various types of tours, many of which select an arbitrary or function-driven path. All of the discrete techniques also highlight a specific feature. For EDA it is desirable to give the analyst the ability to choose the direction to explore. To explore higher dimensional spaces visually, we need _human-in-the-loop_ [@karwowski_international_2006] tools. [@cook_manual_1997] introduces the idea of the _manual_ tour. In a manual tour, an individual variable is selected and its contribution to the projection basis is then controlled. This allows analysts to choose the direction of exploration.

Figure \@ref(fig:manipSp) illustrates a manipulation space. the basis we viewed before is shown in blue and unselected variables in grey on a horizontal plane. while the manipulation space extends above it in red. The contribution that V1 has on the blue projection plane can be controlled as though a hand might manipulate the end of the red line segment. The other variables would perform a constrained rotation, maintain orthogonality of the space.

```{r manipSp, echo = FALSE, out.width = "60%",                             fig.cap = "Visualization of a manipulation space. The projection plane extends horizontally in blue and grey. The manipulation direction in red extends orthogonal to this. Variable 1 is selected as the manipulation variable. Its contribution to the projection plane (blue) is controlled by its position in the manipulation space (red). If the red segment is manipulated all variable change due to orthogonally-constrained rotation."}
knitr::include_graphics("./figures/manipSp.png")
```

<!-- knowledge gap -->
The discrete methods above identity discrete bases that highlight some feature. The above tours can help convey more continuity of structure through many small changes in the basis. For EDA it is desirable to give the analyst the ability to choose the direction to explore.  

## Steering 2-D projections

The manual tour can play a predefined manual path or be used interactively, where the user defines each subsequent step while viewing the current projection. The later, human-in-the-loop method we define as _User-Controlled Steering_ (UCS) specifically as the interactive, human-in-the-loop application of the manual tour.

User-control manipulation around identified projections of interest theoretically allows for a better understanding of the variables contributing to the structure. However, the level of abstraction and the sheer number of basis permutations is formidable. The idea that UCS will provide digestible improvements to the understanding of structure should be validated.


## Research objectives

Data and models are typically high-dimensional, with many variables and parameters. Developing new methods to visualize high dimensions has been a pursuit of statisticians, computer scientists and visualization researchers for decades. Their continues to be tension and back-and-forth on automated- and manual- analysis. Hardware advances allow for more realistic virtual-, augmented-, and mixed- environments with ever-increasing computing power. The degree of analyst choice and interaction with the display dimension should be explored. The primary research objectives (RO) can then be summarized as the following.

Overall objective: **Can a geodesic interpolator be used to help analysts understand linear projections of data, and explore the sensitivity of structure in the projection to the variables contributing to the projection? **

1. **How do we define a geodesic interpolator be used to add and remove variables smoothly from a 2D linear projection of data?**\
An algorithm for the manual tour is discussed in @cook_manual_1997. The algorithm will be adapted to create the geodesic interpolator. Input will be a single projection, a full $p$-dimensional data matrix, and a choice of variable to control. The implementation will be in R. 

2. **Do analysts understand the relationship between variables and structure in a 2D linear projection better when the geodesic interpolator is available?**\
Current practice for high-dimensional data is to make a single low-dimensional representation, with a method such as principal component analysis (PCA). Often just the first two principal components are shown, which is equivalent to a 2D projection. This technique is also called a biplot. Another more rarely used technique is a tour, which shows an animation of 2D projections. It can be used to get an overview of the structure in the multivariate space, but it is difficult to assess the importance of variables to a particularly interesting low-dimensional structure. A human subject study has been designed and conducted to assess the learning about the importance of variables, from each of these techniques. 

3. **Can we define a geodesic interpolator for 3D projections, so that the technology can be implemented in modern virtual reality environments?<!-- How can the manual tour be extended to 3D?-->**\
The cutting edge of visualization research today is in virtual environments, as technology has advanced to make this accessible to the masses. It is interesting to explore how analysis with 3D graphics operates in comparison with 2D graphics. Building a geodesic interpolator for 3D projections extends the technology from 2D to 3D, and will allow us to compare the benefits or not, of the new environment for analyzing with multivariate data.

4. **Does 3D provide advantages over 2D, when exploring low-dimensional projections, for understanding structure in high-dimensional data? <!-- manual tours provide benefits over alternatives?-->**\
@gracia_new_2016 compares analyst tasks between 2- and 3-D scatterplots. They find modest accuracy and error improvements for distance perception and outlier identification in favor of 3D at the cost of a relatively small increase in task time. @nelson_xgobi_1998 similarly compare a 2D projection and its 3D  manipulation space. They find a slight advantage in the sphere test and a large advantage in the cluster test in favor of the 3D manipulation space. A human subjects experiment will be conducted to assess the sensitivity analysis techniques in a 2D vs 3D environment.


## Methodology

This research is interdisciplinary; touring was developed by statisticians to explore physics data. Modern advances in hardware from information technology allow for 3D rending in higher quality and immersion than previously possible. 
<!-- The original motivation for the grand tour was for use on particle physics [@fisherkeller_prim-9:_1974]. Likewise, applications in high energy physics identified [@cook_dynamical_2018]. -->

The research corresponding with RO #1 entails _algorithm design_ following and further clarifying the work done in @cook_manual_1997. In the application of the manual tour, we clarified the creation of the rotation matrix. The key to the matrix is to specify the 2 axes of rotation for the manipulation space and apply Rodrigues' rotation formula [@rodrigues_lois_1840]. In the application, attention was given to both pre-compiled tour and human-in-the-loop UCS. We provide an open-source version of the manual tour in the R package, `spinifex`, which has since been published on CRAN. This forms the foundation for future work in the remaining objectives.

For RO #2 is a controlled _experimental study_ to explore the efficacy of interactive UCS compared with the benchmarks factors of PCA and the grand tour. This is designed as a within-participant study where each participant performs all factors. the study is balanced by assigning participants into one of 3 groups where the factor order is controlled by a Latin square while simulation order remains the same. The details are discussed in finer detail in section (#sec:expStudy), below.

The research for RO #3 involves _algorithm design_ extending the current 2D manual tour into a 3D project. For a 2D projection, the axes basis is rotated through a 3D 'manipulation space'. In a 3D projection, such a space requires 4 dimensions. Theoretically, after the addition of a new angle of rotation, the rotation matrix must be extended to accommodate a new dimension and angle parameter. This also means that analysts have another parameter to define, further increasing their already sizable input-volume. 

<!-- #TODO: _experimental study_  FOR RO4 -->

# Progress since confirmation

During the candidature confirmation review (27 March 2019) we discussed exploratory data analysis, visualization of high dimensional spaces, covered the literature for tours and 3D rendering for information perception. We concluded with a process for a manual tour that allows for user-controlled steering. The appending the document was a mostly complete R package and respective paper providing an open-source application as well as clarifying the rotation matrix that was outlined in @cook_manual_1997.

## Publication

The paper has since been accepted in the R Journal and it currently undergoing editorial review. This will be published in the first issue of 2020 and available at [journal.r-project.org](https://journal.r-project.org/).
<!-- Is there a pre-print version to cite? -->

## Software

The R package, `spinifex (v0.1.0)` [@spyrison_spinifex_2019], has been approved and hosted for public use on the Comprehensive R Archival Network, CRAN (cran.r-project.org/web/packages/spinifex/)(https://cran.r-project.org/web/packages/spinifex/index.html).

New functionality has been added to the development branch, specifically around the interactive use. A user application is developed with `shiny`[@chang_shiny:_2018]. It allows users to explore their data without the need for coding familiarity. It features interactive or precompiled manual touring. It also contains a gallery for flagging bases which can then further be reviewed or saved as .gif and .png files.

## Experimental study {#sec:expStudy}

<!-- Design completed, pilot testing underway, experiment to be rolled out in the coming weeks. -->
<!-- [include in supplementary material] -->

The prominent appeal of the manual tour is that it allows users to control the contributions of individual variables. In theory, this should enable the finer exploration of features of interest. The hypothesis we will study is _Does the finer control afforded by the manual tour improve the ability of the analyst to understand the importance of variables contributing to the structure?_

We list out an abbreviated summary of the experimental design in the subsections below. A more detailed draft of the working paper is included as an appendix. 


### Groups {#sec:groups}

Each participant will be randomly split into one of three even groups. The group controls the order of the factors that the participant was evaluated in for a latin square of the 3 factors. For instance, the order of the first group was PCA, grand, manual. Group level only impacts the order the factors are displayed while task, block, and simulation order will remain the same. 


```{r designExample, echo = F, out.width = '80%',                             fig.cap = "Example case. Person 'A' is assigned to group 2, where they will use factor 2 (grand tour) for the first period. They perform 3 block difficulties of task 1 on simulations of increasing difficulty. Then 3 block difficulties of task 2 on unique simulations sampled from the same distributions of increasing difficulty. After this, they proceed to period 2, where they are use factor 3 (manual tour) to perform 3 block difficulties of each task. Lastly, in the third period, they use factor 1 (PCA) to perform the tasks."}
knitr::include_graphics("./figures/experimental_design_personA.PNG")

```

### Factors {#sec:factors}

<!-- factors: PCA, grand, manual -->
We will explore performance across three factors. The first factor is Principal Component Analysis (PCA). The second factor is an animated walk of interpolation frames between target bases, called a _grand_ tour. The third factor allows for the manual control of the individual variable's contribution to the projection, performing a _manual_ tour.

<!-- Plot and axes -->
All factors are shown as a scatterplot. The basis axes projection was also illustrated to the left of the plot. They are shown in a unit circle and show the magnitude and direction each variable contributes to the projection.

<!-- interface differences -->
The user interface was kept the same whenever possible, but the control inputs do change slightly to accommodate the differences between factors. The inputs for  PCA select a pair of principal components to display on the x- and y-axes. The manual tour had the same axes selection, with the addition of a drop-down bar and slider control selecting the manipulation variable and magnitude. The grand tour comes precompiled as an animation of a 15 second showing 90 frames at 6 frames per second. The user can control the location or play/pause the animation at will.


### Tasks {#sec:tasks}

Within each factor, participants will perform 2 tasks. The first task asks participants to identify the number of clusters present in unsupervised data. This task served as a standard for assessing the general aptitude for this sort of high dimensional analysis as it was simpler. In application, linear discriminant analysis [@fisher_use_1936] or penalized discriminant analysis [@hastie_penalized_1995] are better suited for classifying such unsupervised data.

The second task is focused on the hypothesis of the study, it asks participants to identify any/all variables that were very important and somewhat important for distinguishing a given cluster from the others. For instance, which variables are very- and somewhat- important for distinguishing clusters 'A' and 'B'.


### Block difficulty {#sec:blocks}

Participants will be randomly assigned to 1 of 3 even groups. Each group has a  different factor order containing all factors. Both tasks will be performed in the same order. Each task will have 3 repetitions performed on new simulations that were drawn from 3 parameterizations in increasing difficulty. Each participant will go through the simulations in the same order, while their factor order will vary. Fixing block difficulty order while varying factors should mitigate potential learning bias.

### Pilot study results

__#TODO:__


# Proposed thesis structure

## Thesis structure

- Introduction -- 60%
- Literature review -- 80%
- Manual tour and user-controlled steering -- 90%
- Experimental study -- 60%
- The extension of the manual tour to 3D -- 5%
- Conclusion and future plans -- 0%

__Proposed research timeline__

```{r timeline, echo=FALSE, out.width = "100%", out.extra = '', fig.cap = "Proposed research timeline."}
# fig.pos="H" # Holds the figure postion reltive to local content
knitr::include_graphics("figures/phd_timeline.PNG")
```

## Program requirements
<!-- http://www.monash.edu/pubs/2018handbooks/aos/information-technology-phd-program/ -->

- WES Academic record
    - FIT5144: 2019 S1+2, **In progress**, extended to the pre-submission seminar with the unit coordinator for the usual 2 opportunities to complete.
        - Hours: 147>120 hours __Tracked__, missing the following requirments (12 hr total)
        - _Needed:_ CYR 2 (A & B) -- 2x 3hr 
        - _Needed:_ Faculty of IT Workshop 1 and 3 on Ethical Research and Publishing -- 2x 3hr
    - FIT5113: 2018 S2, **Exemption**
    <!-- (submitted:08/2018, recorded 4/2019) -->
    - FIT6021: 2018 S2, **Completed** with distinction
- myDevelopment - IT: Monash Doctoral Program - Compulsory Module
    - Monash graduate research student induction: **Completed** 
    <!-- last assesed: 20/02/2018 -->
    - Research Integrity - Choose the Option most relevant: **Completed** 
    <!-- Last Accessed:    20/02/2018 (2 of 4 required & completed) -->
    - Faculty Induction: **Completed** 
    <!-- marked completed, online class "08/05/2019 @ 09:45 for 3hr 15min" -->
    <!-- previously: **Content unavailable** (01/04/2019: "Currently being updated and will be visible in this section soon") -->
    

# Potential issues for panel to consider

## Funding for human subjects

- Beverage voucher: \$6 x 25 people (est) = \$150  

## Support for conference travel

__Conferences:__\
\
CHI 2021: May 8-13, 2021 Yokohama, Japan\
submission: Thursday Sep. 10, 2020\
<!-- (+ 1wk for full) -->
https://chi2021.acm.org/ \
\
IEEE VAST - VAST 2020: 25-30 October 2020 Salt Lake City, Utah, USA\
submission: Saturday, March 21, 2020\
<!-- (+ 10 days for full) VAST - Empirical Study\ -->
http://ieeevis.org/year/2020/info/call-participation/vast-paper-types


# Acknowledgements {#sec:acknowledgements}

This report was created in `R` [@r_core_team_r:_2019] using `rmarkdown` [@xie_r_2018].

For version control, transparency, and reproducibility, the source files are made available found at [github.com/nspyrison/mid_candidature](https://github.com/nspyrison/mid_candidature).


# References 